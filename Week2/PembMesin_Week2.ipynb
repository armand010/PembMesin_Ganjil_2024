{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYTsN8HBQjqL0c6BqLc0rf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armand010/PembMesin_Ganjil_2024/blob/main/PembMesin_Week2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "w_gfAfU7vw8h",
        "outputId": "1eb5a133-60c2-4b26-daf2-201afdc8d342",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah label data asli:\n",
            "diagnosis\n",
            "-0.770609    357\n",
            " 1.297676    212\n",
            "Name: count, dtype: int64\n",
            "Jumlah label data train:\n",
            "diagnosis\n",
            "-0.770609    290\n",
            " 1.297676    165\n",
            "Name: count, dtype: int64\n",
            "Jumlah label data test:\n",
            "diagnosis\n",
            "-0.770609    67\n",
            " 1.297676    47\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-c5ad768e03ac>:177: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dfD['diagnosis'] = le.fit_transform(dfD['diagnosis'])\n",
            "<ipython-input-31-c5ad768e03ac>:181: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dfD['diagnosis'] = std.fit_transform(dfD[['diagnosis']])\n"
          ]
        }
      ],
      "source": [
        "# !pip install Pillow\n",
        "# PRAKTIKUM 1\n",
        "# import pandas as pd\n",
        "\n",
        "# data = 'Titanic-Dataset-fixed.csv' # path dataset\n",
        "# df = pd.read_csv(data) # load dataset\n",
        "\n",
        "# df.head()\n",
        "\n",
        "# # Age - mean\n",
        "# df['Age'].fillna(value=df['Age'].mean(), inplace=True)\n",
        "\n",
        "# # Cabin - \"DECK\"\n",
        "# df['Cabin'].fillna(value=\"DECK\", inplace=True)\n",
        "\n",
        "# # Embarked - modus\n",
        "# df['Embarked'].fillna(value=df['Embarked'].mode, inplace=True)\n",
        "\n",
        "# df.isnull().sum()\n",
        "\n",
        "# PRAKTIKUM 2\n",
        "# import pandas as pd\n",
        "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# dpath = 'Titanic-Dataset-fixed.csv'\n",
        "# df = pd.read_csv(dpath)\n",
        "# # df.head()\n",
        "\n",
        "# df = df[['Survived', 'Pclass', 'Age', 'Sex', 'Cabin']]\n",
        "# # df.head()\n",
        "\n",
        "# le = LabelEncoder() # membuat objek dari LabelEncoder\n",
        "# df['Sex'] = le.fit_transform(df['Sex']) # proses encoding\n",
        "# df['Cabin'] = le.fit_transform(df['Cabin']) # proses encoding\n",
        "# # df.head()\n",
        "\n",
        "# std = StandardScaler()\n",
        "# df['Age'] = std.fit_transform(df[['Age']])\n",
        "# df.head()\n",
        "\n",
        "# PRAKTIKUM 3\n",
        "# Random Split\n",
        "# import pandas as pd\n",
        "\n",
        "# df = pd.read_csv('Titanic-Dataset-selected.csv')\n",
        "# # df.head()\n",
        "\n",
        "# # Split data\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Split data training dan dan lainnya\n",
        "# # data lainnya, akan kita split lagi menjadi validasi dan testing.\n",
        "# # Rasio yang akan kita gunakan adalah 8:1:1\n",
        "# df_train, df_unseen = train_test_split(df, test_size=0.2, random_state=0)\n",
        "\n",
        "# # Split lagi antara validasi dan testing\n",
        "# df_val, df_test = train_test_split(df_unseen, test_size=0.5, random_state=0)\n",
        "\n",
        "# # Cek masing-masing ukuran data\n",
        "\n",
        "# print(f'Jumlah data asli: {df.shape[0]}')\n",
        "# print(f'Jumlah data train: {df_train.shape[0]}')\n",
        "# print(f'Jumlah data val: {df_val.shape[0]}')\n",
        "# print(f'Jumlah data test: {df_test.shape[0]}')\n",
        "\n",
        "# # Cek rasio tiap label\n",
        "# print('=========')\n",
        "# print(f'Jumlah label data asli:\\n{df.Survived.value_counts()}')\n",
        "# print(f'Jumlah label data train:\\n{df_train.Survived.value_counts()}')\n",
        "# print(f'Jumlah label data val:\\n{df_val.Survived.value_counts()}')\n",
        "# print(f'Jumlah label data test:\\n{df_test.Survived.value_counts()}')\n",
        "\n",
        "# Stratified Split\n",
        "# import pandas as pd\n",
        "\n",
        "# df2 = pd.read_csv('Titanic-Dataset-selected.csv')\n",
        "# # df2.head()\n",
        "\n",
        "# # Split data\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Split data training dan dan lainnya\n",
        "# # data lainnya, akan kita split lagi menjadi validasi dan testing.\n",
        "# # Rasio yang akan kita gunakan adalah 8:1:1\n",
        "# df2_train, df2_unseen = train_test_split(df2, test_size=0.2, random_state=0, stratify=df['Survived'])\n",
        "\n",
        "# # Split lagi antara validasi dan testing\n",
        "# df2_val, df2_test = train_test_split(df2_unseen, test_size=0.5, random_state=0, stratify=df_unseen['Survived'])\n",
        "\n",
        "# # Cek masing-masing ukuran data\n",
        "\n",
        "# print(f'Jumlah label data asli:\\n{df2.Survived.value_counts()}')\n",
        "# print(f'Jumlah label data train:\\n{df2_train.Survived.value_counts()}')\n",
        "# print(f'Jumlah label data val:\\n{df2_val.Survived.value_counts()}')\n",
        "# print(f'Jumlah label data test:\\n{df2_test.Survived.value_counts()}')\n",
        "\n",
        "# Cross Validation 1\n",
        "# import pandas as pd\n",
        "\n",
        "# df3 = pd.read_csv('Titanic-Dataset-selected.csv')\n",
        "# # df3.head()\n",
        "\n",
        "# # Implementasi k-fold cross validation (random) dengan training dan testing saja\n",
        "# from sklearn.model_selection import KFold\n",
        "\n",
        "# # inisiasi obyek kfold\n",
        "# kf = KFold(n_splits=4)\n",
        "# print(f'Jumlah fold: {kf.get_n_splits()}')\n",
        "# print(f'Obyek KFold: {kf}')\n",
        "\n",
        "# # Lakukan splitting dengan KFold\n",
        "# kf_split = kf.split(df3)\n",
        "# print(f'Jumlah data df: {df.shape[0]}')\n",
        "\n",
        "# # cek index data tiap fold\n",
        "# for train_index, test_index in kf_split:\n",
        "#     print(f'Index train: {train_index} | Index test: {test_index}')\n",
        "\n",
        "# Cross Vaalidation 2\n",
        "# import pandas as pd\n",
        "\n",
        "# df4 = pd.read_csv('Titanic-Dataset-selected.csv')\n",
        "# df4.head()\n",
        "\n",
        "# # Implementasi k-fold cross validation (random) dengan training, validation, dan testing data\n",
        "# from sklearn.model_selection import train_test_split, KFold\n",
        "\n",
        "# # Split dulu antara data training dan testing dengan train_test_split\n",
        "# # Rasio 8:2 untuk training dan testing\n",
        "# df4_train, df4_test = train_test_split(df4, test_size=0.2, random_state=0)\n",
        "\n",
        "# # inisiasi obyek kfold\n",
        "# kf2 = KFold(n_splits=4)\n",
        "# print(f'Jumlah fold: {kf2.get_n_splits()}')\n",
        "# print(f'Obyek KFold: {kf2}')\n",
        "\n",
        "# # Lakukan splitting dengan KFold untuk data df_training\n",
        "# # Dengan acara ini, kita masih memiliki data testing untuk keperluan pengujian model\n",
        "# # namun tetap dapat melakukan evaluasi dengan menggunakan data validasi\n",
        "# kf2_split = kf2.split(df4_train)\n",
        "# print(f'Jumlah data df_train: {df4_train.shape[0]}')\n",
        "\n",
        "# # cek index data tiap fold\n",
        "# for train_index, test_index in kf2_split:\n",
        "#     print(f'Index train: {train_index} | Index test: {test_index}')\n",
        "\n",
        "# PRAKTIKUM 4\n",
        "# from PIL import Image\n",
        "\n",
        "# img = Image.open('Lenna_(test_image).png')\n",
        "# img.show() # tampilkan gambar\n",
        "# display(img) # metode alternatif tampilkan gambar\n",
        "\n",
        "# # Ekstrak setiap channel red, green, blue\n",
        "# r, g, b = img.split()\n",
        "\n",
        "# # Cek panjang ukuran channel red\n",
        "# print(len(r.histogram()))\n",
        "\n",
        "# # Cetak fitur histogram pada channel red\n",
        "# print(r.histogram())\n",
        "\n",
        "# TUGAS PRAKTIKUM\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "data = 'wbc.csv'\n",
        "df = pd.read_csv(data)\n",
        "\n",
        "df.head()\n",
        "\n",
        "# Memakai kolom diagnosis saja\n",
        "df = df[['diagnosis']]\n",
        "\n",
        "# Encoding pada kolom diagnosis\n",
        "le = LabelEncoder()\n",
        "df['diagnosis'] = le.fit_transform(df['diagnosis'])\n",
        "\n",
        "# Standarisasi pada kolom diagnosis\n",
        "std = StandardScaler()\n",
        "df['diagnosis'] = std.fit_transform(df[['diagnosis']])\n",
        "\n",
        "# Split Data testing dan test dengan rasio 8:2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)\n",
        "\n",
        "print(f'Jumlah label data asli:\\n{df.diagnosis.value_counts()}')\n",
        "print(f'Jumlah label data train:\\n{df_train.diagnosis.value_counts()}')\n",
        "print(f'Jumlah label data test:\\n{df_test.diagnosis.value_counts()}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OMLYdN5YI9Qw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}